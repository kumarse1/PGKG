# YOUR ORIGINAL IMPORTS - UNCHANGED
import streamlit as st
import pandas as pd
import networkx as nx
from pyvis.network import Network
import tempfile
import os
from sqlalchemy import create_engine
import psycopg2
from streamlit_agraph import agraph, Node, Edge, Config

# NEW ADDITION: LLM integration imports for chat feature
import requests
from requests.auth import HTTPBasicAuth

# NEW ADDITION: LLM Configuration for chat functionality
LLM_API_URL = "https://your-llm-endpoint.com/v1/chat/completions"
LLM_USERNAME = "your_username_here"  # Replace with actual username
LLM_PASSWORD = "your_password_here"  # Replace with actual password

# YOUR ORIGINAL DATABASE CONNECTION - UNCHANGED
# --- Connect to PostgreSQL ---
db_user = ""
db_password = ""
db_host = ""
db_port = ""
db_name = ""
table_name = "kg_application_data"

engine = create_engine(f"postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}")

# --- Database Connection ---
@st.cache_resource
def get_connection():
    return psycopg2.connect(
        dbname=db_name, user=db_user, password=db_password, host=db_host,
        port=db_port
    )

# YOUR ORIGINAL NORMALIZE FUNCTION - UNCHANGED
def normalize_df(df):
    int_cols = df.select_dtypes(include=['int64']).columns
    df[int_cols] = df[int_cols].astype('int32')
    
    float_cols = df.select_dtypes(include=['float64']).columns
    df[float_cols] = df[float_cols].astype('float32')
    
    return df

# YOUR ORIGINAL LOAD DATA FUNCTION - UNCHANGED
@st.cache_data
def load_data():
    conn = get_connection()
    _nodes = pd.read_sql("SELECT * FROM kg_nodes", conn)
    _edges = pd.read_sql("SELECT * FROM kg_edges", conn)
    
    nodes = normalize_df(_nodes)
    edges = normalize_df(_edges)
    
    return nodes, edges

def to_native_type(value):
    if pd.isna(value):
        return ""
    return str(value)

# YOUR ORIGINAL BUILD SUBGRAPH FUNCTION - MODIFIED to support "All" option
def build_subgraph(nodes_df, edges_df, selected_node_id, direction):
    G = nx.DiGraph()
    
    center = nodes_df[nodes_df.node_id == selected_node_id].iloc[0]
    G.add_node(
        to_native_type(center.node_id),
        label=to_native_type(center.label),
        group=to_native_type(center.label),
        title=f"{center['name']}"
    )
    
    # MODIFIED: Added "All" option support - now checks for "All" in addition to original options
    if direction in ("Outgoing", "Both", "All"):  # ADDED: "All" option
        out_edges = edges_df[edges_df.source_node_id == selected_node_id]
        for _, row in out_edges.iterrows():
            target = nodes_df[nodes_df.node_id == row.target_node_id]
            if not target.empty:
                tgt = target.iloc[0]
                G.add_node(
                    to_native_type(tgt.node_id),
                    label=to_native_type(tgt.label),
                    group=to_native_type(tgt.label),
                    title=f"{tgt['name']}"
                )
                G.add_edge(
                    to_native_type(center.node_id),
                    to_native_type(tgt.node_id),
                    label=to_native_type(row.relation_type),
                    title=f"{tgt['name']}"
                )

    # MODIFIED: Added "All" option support - now checks for "All" in addition to original options
    if direction in ("Incoming", "Both", "All"):  # ADDED: "All" option
        in_edges = edges_df[edges_df.target_node_id == selected_node_id]
        for _, row in in_edges.iterrows():
            source = nodes_df[nodes_df.node_id == row.source_node_id]
            if not source.empty:
                src = source.iloc[0]
                G.add_node(
                    to_native_type(src.node_id),
                    label=to_native_type(src.label),
                    group=to_native_type(src.label),
                    title=f"{src['name']}"
                )
                G.add_edge(
                    to_native_type(center.node_id),
                    to_native_type(src.node_id),
                    label=to_native_type(row.relation_type),
                    title=f"{src['name']}"
                )

    return G

# NEW ADDITION: LLM query function for chat feature
def query_llm(question, context_data):
    """
    NEW FUNCTION: Handles LLM queries for chat functionality
    Sends context about selected node and graph to LLM
    """
    try:
        # Format context including chat history
        context_text = f"""
        Knowledge Graph Context:
        - Selected Node: {context_data['selected_node']}
        - Connected Nodes: {context_data['connected_nodes']}
        - Direction Filter: {context_data['direction']}
        - Total Nodes: {context_data['total_nodes']}
        - Total Edges: {context_data['total_edges']}
        
        Previous Chat:
        {format_chat_history(context_data.get('chat_history', []))}
        
        Current Question: {question}
        """
        
        payload = {"messages": [{"role": "user", "content": context_text}]}
        
        response = requests.post(
            LLM_API_URL,
            json=payload,
            auth=HTTPBasicAuth(LLM_USERNAME, LLM_PASSWORD),
            headers={"Content-Type": "application/json"},
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            return result.get("choices", [{}])[0].get("message", {}).get("content", "No response received")
        else:
            return f"LLM API Error: {response.status_code} - {response.text}"
        
    except Exception as e:
        return f"LLM query failed: {str(e)}"

# NEW ADDITION: Helper function to format chat history for LLM context
def format_chat_history(chat_history):
    """
    NEW FUNCTION: Formats previous chat messages for LLM context
    Limits to last 5 exchanges to avoid token limits
    """
    if not chat_history:
        return "No previous conversation."
    
    formatted = []
    for role, message in chat_history[-5:]:  # Last 5 messages
        formatted.append(f"{role.title()}: {message}")
    return "\n".join(formatted)

# YOUR ORIGINAL UI LAYOUT START - UNCHANGED
st.set_page_config(layout="wide")

st.title("Knowledge Graph: Node-Centered View with Edge Direction")

nodes_df, edges_df = load_data()

label_options = sorted(nodes_df["label"].unique().tolist())

selected_label = st.selectbox("Select Node Label", label_options)

filtered_nodes = nodes_df[nodes_df.label == selected_label]

selected_name = st.selectbox("Select Node Name", 
                            sorted(filtered_nodes["name"].unique()))

selected_node = filtered_nodes[filtered_nodes["name"] == selected_name].iloc[0]
selected_node_id = selected_node.node_id

# MODIFIED: Changed from radio to selectbox and added "All" option
# Direction Toggle - CHANGED from st.radio to st.selectbox with "All" option
direction = st.selectbox(
    "Show edges in which direction?",
    ["All", "Outgoing", "Incoming", "Both"],  # ADDED: "All" as first option
    index=0,  # CHANGED: Default to "All" instead of index=2
    help="All: Show all connections, Outgoing: edges from this node, Incoming: edges to this node, Both: same as All"
)

# YOUR ORIGINAL PROPERTIES AND GRAPH SECTION - UNCHANGED
# üîç Properties and Graph
st.markdown("### Node Properties")

st.json(selected_node.properties if hasattr(selected_node, 'properties') and selected_node.properties else 
        selected_node.properties else {})

st.markdown("### Graph View")

html_file = build_subgraph(nodes_df, edges_df, selected_node_id, direction)

with open(html_file, "r", encoding="utf-8") as f:
    html = f.read()

# YOUR ORIGINAL HTML DISPLAY - UNCHANGED
st.components.v1.html(html, height=650, scrolling=True)

# NEW ADDITION: Chat functionality section
st.markdown("---")  # Visual separator
st.markdown("### üí¨ Chat About Your Knowledge Graph")

# NEW: Initialize chat history in session state
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

# NEW: Clear chat button
col1, col2 = st.columns([1, 4])
with col1:
    if st.button("üóëÔ∏è Clear Chat"):
        st.session_state.chat_history = []
        st.rerun()

# NEW: Display chat history
if st.session_state.chat_history:
    st.markdown("**Conversation:**")
    for role, message in st.session_state.chat_history:
        if role == "user":
            st.markdown(f"**You:** {message}")
        else:
            st.markdown(f"**AI:** {message}")
        st.markdown("---")

# NEW: Chat input form
with st.form("chat_form", clear_on_submit=True):
    st.markdown("**Ask a question about the knowledge graph:**")
    question = st.text_input(
        "Your question:",
        placeholder="e.g., 'What connects to this node?' or 'Explain the relationships'"
    )
    
    submitted = st.form_submit_button("üí¨ Send Message", type="primary")
    
    if submitted and question.strip():
        # Add user message to chat history
        st.session_state.chat_history.append(("user", question))
        
        with st.spinner("Thinking..."):
            # Calculate connected nodes count for context
            if direction == "All":
                connected_count = len(edges_df[
                    (edges_df.source_node_id == selected_node_id) | 
                    (edges_df.target_node_id == selected_node_id)
                ])
            elif direction == "Outgoing":
                connected_count = len(edges_df[edges_df.source_node_id == selected_node_id])
            elif direction == "Incoming":
                connected_count = len(edges_df[edges_df.target_node_id == selected_node_id])
            else:  # Both
                connected_count = len(edges_df[
                    (edges_df.source_node_id == selected_node_id) | 
                    (edges_df.target_node_id == selected_node_id)
                ])
            
            # Prepare context data for LLM
            context_data = {
                "selected_node": selected_name,
                "connected_nodes": connected_count,
                "direction": direction,
                "total_nodes": len(nodes_df),
                "total_edges": len(edges_df),
                "chat_history": st.session_state.chat_history[:-1]  # Previous messages only
            }
            
            # Get LLM response
            response = query_llm(question, context_data)
            
            # Add AI response to chat history
            st.session_state.chat_history.append(("ai", response))
            
            st.rerun()

# NEW: Instructions for setup
with st.expander("‚ÑπÔ∏è Setup Instructions", expanded=False):
    st.markdown("""
    **To enable chat functionality:**
    
    1. **Database**: Add your PostgreSQL credentials in the variables at the top
    2. **LLM Service**: Update the LLM configuration:
       - `LLM_API_URL`: Your LLM endpoint
       - `LLM_USERNAME`: Your LLM service username  
       - `LLM_PASSWORD`: Your LLM service password
    
    **What's New:**
    - ‚úÖ Chat interface for asking questions about your graph
    - ‚úÖ "All" option in direction filter (shows all connections)
    - ‚úÖ LLM receives context about selected node and graph statistics
    - ‚úÖ Chat history maintained during session
    """)
